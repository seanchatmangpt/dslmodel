{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T03:21:09.184752Z",
     "start_time": "2024-10-08T03:21:09.177436Z"
    }
   },
   "source": [
    "from pydantic import Field\n",
    "\n",
    "from dslmodel import DSLModel, init_instant\n",
    "from typing import List, Type\n",
    "from functools import reduce\n",
    "import logging\n",
    "\n",
    "def from_prompt_chain(initial_prompt: str, models: List[Type[DSLModel]]) -> List[DSLModel]:\n",
    "    \"\"\"\n",
    "    Executes a chain of DSLModel.from_prompt calls, where the result of one is passed as the prompt to the next.\n",
    "\n",
    "    Args:\n",
    "        initial_prompt (str): The initial prompt to start the chain.\n",
    "        models (List[Type[DSLModel]]): A list of DSLModel subclasses to be instantiated in sequence.\n",
    "\n",
    "    Returns:\n",
    "        List[DSLModel]: A list of instantiated DSLModel objects resulting from the chain.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if not logger.handlers:\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    def chain(accumulator: List[DSLModel], model_class: Type[DSLModel]) -> List[DSLModel]:\n",
    "        \"\"\"\n",
    "        Helper function for reduce to execute from_prompt and accumulate results.\n",
    "\n",
    "        Args:\n",
    "            accumulator (List[DSLModel]): The list of previously instantiated models.\n",
    "            model_class (Type[DSLModel]): The current DSLModel subclass to instantiate.\n",
    "\n",
    "        Returns:\n",
    "            List[DSLModel]: Updated list of instantiated models.\n",
    "        \"\"\"\n",
    "        # Determine the prompt for the current model\n",
    "        if not accumulator:\n",
    "            prompt = initial_prompt\n",
    "            logger.debug(f\"Initial prompt for {model_class.__name__}: {prompt}\")\n",
    "        else:\n",
    "            # Assuming each model has a 'generated_text' attribute or similar\n",
    "            # Adjust the attribute name based on your DSLModel definitions\n",
    "            previous_model = accumulator[-1]\n",
    "            prompt = str(previous_model)\n",
    "            logger.debug(f\"Prompt for {model_class.__name__} from previous model: {prompt}\")\n",
    "\n",
    "        try:\n",
    "            # Instantiate the current model using from_prompt\n",
    "            model_instance = model_class.from_prompt(prompt)\n",
    "            logger.info(f\"Successfully instantiated {model_class.__name__}\")\n",
    "            return accumulator + [model_instance]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error instantiating {model_class.__name__} with prompt '{prompt}': {e}\")\n",
    "            # Depending on requirements, you can choose to append None or skip\n",
    "            return accumulator + [None]\n",
    "\n",
    "    # Use reduce to apply the chain function across the models list\n",
    "    results = reduce(chain, models, [])\n",
    "\n",
    "    return results\n"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:21:09.752009Z",
     "start_time": "2024-10-08T03:21:09.747186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Task(DSLModel):\n",
    "    \"\"\"\n",
    "    Represents a task within a work session.\n",
    "    \"\"\"\n",
    "    name: str = Field(..., description=\"The name of the task.\")\n",
    "    description: Optional[str] = Field(None, description=\"A brief description of the task.\")\n",
    "    duration_minutes: int = Field(..., description=\"Estimated duration to complete the task.\")\n",
    "    status: str = Field(\"Pending\", description=\"Current status of the task (e.g., Pending, In Progress, Completed).\")\n",
    "\n",
    "\n",
    "class SMARTGoal(DSLModel):\n",
    "    \"\"\"\n",
    "    Represents a SMART (Specific, Measurable, Achievable, Relevant, Time-bound) goal.\n",
    "    \"\"\"\n",
    "    title: str = Field(..., description=\"The title of the SMART goal.\")\n",
    "    specific: str = Field(..., description=\"Specific details of the goal.\")\n",
    "    measurable: str = Field(..., description=\"Metrics to measure the goal's progress.\")\n",
    "    achievable: str = Field(..., description=\"Criteria that make the goal achievable.\")\n",
    "    relevant: str = Field(..., description=\"Relevance of the goal to broader objectives.\")\n",
    "    time_bound: str = Field(..., description=\"Time frame to achieve the goal.\")\n"
   ],
   "id": "ad377114a577a967",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:21:12.270014Z",
     "start_time": "2024-10-08T03:21:10.387805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the initial prompt\n",
    "initial_prompt = \"Grocery shopping for milk, cheese, and bread.\"\n",
    "\n",
    "# Define the list of models in the desired sequence\n",
    "models_chain = [SMARTGoal, Task]\n",
    "\n",
    "init_instant()\n",
    "\n",
    "# Execute the from_prompt_chain function\n",
    "chain_results = from_prompt_chain(initial_prompt, models_chain)\n",
    "\n",
    "# Access and print the results\n",
    "for idx, result in enumerate(chain_results):\n",
    "    if result:\n",
    "        print(f\"Result {idx + 1} ({result.__class__.__name__}): {result.generated_text}\")\n",
    "    else:\n",
    "        print(f\"Result {idx + 1}: Failed to instantiate the model.\")\n"
   ],
   "id": "ff7830b4843ffe54",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "6f280f270f09a37b",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
