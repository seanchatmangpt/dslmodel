{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:13:09.543554Z",
     "start_time": "2024-10-18T01:13:08.513097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import Field\n",
    "\n",
    "from dslmodel import DSLModel, init_instant\n",
    "from typing import List, Type\n",
    "from typing import Optional\n",
    "\n",
    "class Task(DSLModel):\n",
    "    \"\"\"\n",
    "    Represents a task within a work session.\n",
    "    \"\"\"\n",
    "    name: str = Field(..., description=\"The name of the task.\")\n",
    "    description: Optional[str] = Field(None, description=\"A brief description of the task.\")\n",
    "    duration_minutes: int = Field(..., description=\"Estimated duration to complete the task.\")\n",
    "    status: str = Field(\"Pending\", description=\"Current status of the task (e.g., Pending, In Progress, Completed).\")\n",
    "\n",
    "\n",
    "class SMARTGoal(DSLModel):\n",
    "    \"\"\"\n",
    "    Represents a SMART (Specific, Measurable, Achievable, Relevant, Time-bound) goal.\n",
    "    \"\"\"\n",
    "    title: str = Field(..., description=\"The title of the SMART goal.\")\n",
    "    specific: str = Field(..., description=\"Specific details of the goal.\")\n",
    "    measurable: str = Field(..., description=\"Metrics to measure the goal's progress.\")\n",
    "    achievable: str = Field(..., description=\"Criteria that make the goal achievable.\")\n",
    "    relevant: str = Field(..., description=\"Relevance of the goal to broader objectives.\")\n",
    "    time_bound: str = Field(..., description=\"Time frame to achieve the goal.\")\n"
   ],
   "id": "ad377114a577a967",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:13:09.575522Z",
     "start_time": "2024-10-18T01:13:09.544585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dslmodel import from_prompt_chain\n",
    "\n",
    "# Define the initial prompt\n",
    "initial_prompt = \"Grocery shopping for milk, cheese, and bread.\"\n",
    "\n",
    "# Define the list of models in the desired sequence\n",
    "models_chain = [SMARTGoal, Task]\n",
    "\n",
    "init_instant()\n",
    "\n",
    "# Execute the from_prompt_chain function\n",
    "chain_results = from_prompt_chain(initial_prompt, models_chain)\n",
    "\n",
    "# Access and print the results\n",
    "for idx, result in enumerate(chain_results):\n",
    "    if result:\n",
    "        print(f\"Result {idx + 1} ({result.__class__.__name__}): {result}\")\n",
    "    else:\n",
    "        print(f\"Result {idx + 1}: Failed to instantiate the model.\")\n"
   ],
   "id": "ff7830b4843ffe54",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dslmodel.utils.model_tools:Successfully instantiated SMARTGoal\n",
      "INFO:dslmodel.utils.model_tools:Successfully instantiated Task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (SMARTGoal): title='Grocery shopping for milk, cheese, and bread.' specific='Shopping for milk, cheese, and bread.' measurable='Number of items purchased (3)' achievable='Within a reasonable time frame (e.g., 1 hour)' relevant='To ensure household supplies are maintained.' time_bound='Within the next 24 hours.'\n",
      "Result 2 (Task): name='Grocery shopping for milk, cheese, and bread.' description='Shopping for milk, cheese, and bread.' duration_minutes=3 status='Pending' title='Grocery shopping for milk, cheese, and bread.' specific='Shopping for milk, cheese, and bread.' measurable='Number of items purchased (3)' achievable='Within a reasonable time frame (e.g., 1 hour)' relevant='To ensure household supplies are maintained.' time_bound='Within the next 24 hours.'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:13:10.174745Z",
     "start_time": "2024-10-18T01:13:09.576088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dslmodel import DSLModel, from_prompt_chain\n",
    "from typing import List\n",
    "from pydantic import Field\n",
    "\n",
    "class Task(DSLModel):\n",
    "    name: str = Field(..., description=\"Name of the task.\")\n",
    "    description: str = Field(..., description=\"Description of the task.\")\n",
    "\n",
    "class SequentialWorkflow(DSLModel):\n",
    "    tasks: List[Task] = Field(..., description=\"List of tasks in sequence.\")\n",
    "\n",
    "# Define the models and initial prompt\n",
    "initial_prompt = \"Plan a product launch sequence.\"\n",
    "models_chain = [Task, Task, Task]\n",
    "\n",
    "# Use from_prompt_chain to create a sequence of tasks\n",
    "workflow_result = from_prompt_chain(initial_prompt, models_chain)\n",
    "print(\"Sequential Workflow:\", workflow_result)\n"
   ],
   "id": "6f280f270f09a37b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dslmodel.utils.model_tools:Successfully instantiated Task\n",
      "INFO:dslmodel.utils.model_tools:Successfully instantiated Task\n",
      "ERROR:dspy.primitives.assertions:\u001B[2m2024-10-18T01:13:09.588054Z\u001B[0m [\u001B[31m\u001B[1merror    \u001B[0m] \u001B[1mAssertionError: You need to create a kwargs dict for Task\n",
      "Validation error:\n",
      "malformed node or string on line 1: <ast.Call object at 0x1264fbad0>\u001B[0m [\u001B[0m\u001B[1m\u001B[34mdspy.primitives.assertions\u001B[0m]\u001B[0m \u001B[36mfilename\u001B[0m=\u001B[35massertions.py\u001B[0m \u001B[36mlineno\u001B[0m=\u001B[35m88\u001B[0m\n",
      "ERROR:dslmodel.dspy_modules.gen_pydantic_instance:Error during validation: You need to create a kwargs dict for Task\n",
      "Validation error:\n",
      "malformed node or string on line 1: <ast.Call object at 0x1264fbad0>\n",
      "Output:\n",
      "Task(name='Product Launch Sequence', description='A planned sequence of events for the product launch.')\n",
      "\u001B[92m18:13:09 - LiteLLM:INFO\u001B[0m: utils.py:3052 - \n",
      "LiteLLM completion() model= llama-3.1-8b-instant; provider = groq\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= llama-3.1-8b-instant; provider = groq\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[92m18:13:10 - LiteLLM:INFO\u001B[0m: utils.py:1000 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "INFO:dslmodel.utils.model_tools:Successfully instantiated Task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Workflow: [Task(name='Product Launch Sequence', description='A planned sequence of events for the product launch.'), Task(name='Product Launch Sequence', description='A planned sequence of events for the product launch.'), Task(name='Product Launch Sequence', description='A planned sequence of events for the product launch.')]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:48:05.903912Z",
     "start_time": "2024-10-18T01:48:03.870289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dslmodel import from_prompt_chain, init_instant, init_text, DSLModel, Field\n",
    "\n",
    "init_text()\n",
    "\n",
    "class InitialDraft(DSLModel):\n",
    "    draft: str = Field(..., description=\"The initial draft content.\")\n",
    "\n",
    "class Feedback(DSLModel):\n",
    "    suggestions: str = Field(..., description=\"Feedback for improving the draft.\")\n",
    "\n",
    "class RefinedDraft(DSLModel):\n",
    "    improved_draft: str = Field(..., description=\"The refined version of the draft.\")\n",
    "\n",
    "class IterationCycle(DSLModel):\n",
    "    initial: InitialDraft = Field(..., description=\"Initial draft of the document.\")\n",
    "    feedback: Feedback = Field(..., description=\"Feedback on the initial draft.\")\n",
    "    refined: RefinedDraft = Field(..., description=\"Refined draft after feedback.\")\n",
    "\n",
    "initial_prompt = \"Write a draft for a blog post on AI ethics.\"\n",
    "models_chain = [InitialDraft, Feedback, RefinedDraft]\n",
    "\n",
    "# Use from_prompt_chain to refine a draft iteratively\n",
    "iteration_result = from_prompt_chain(initial_prompt, models_chain)\n",
    "print(\"Iteration Cycle:\", iteration_result)\n"
   ],
   "id": "e4bb9cb093919050",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-10-17 18:48:03.875\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_debug\u001B[0m:\u001B[36m88\u001B[0m - \u001B[34m\u001B[1mUsing prompt for InitialDraft: Write a draft for a blog post on AI ethics.\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:04.489\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_info\u001B[0m:\u001B[36m83\u001B[0m - \u001B[1mGenerated InitialDraft: draft='The ethics of artificial intelligence is a rapidly evolving field that has garnered significant attention in recent years. As AI systems become increasingly integrated into various aspects of our lives, it is essential to consider the moral implications of their development and deployment. This blog post aims to explore the key issues surrounding AI ethics, including transparency, accountability, and fairness.'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:04.491\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_error\u001B[0m:\u001B[36m98\u001B[0m - \u001B[31m\u001B[1mFailed to generate InitialDraft with prompt 'Write a draft for a blog post on AI ethics.': 'InitialDraft' object has no attribute 'analysis'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:04.492\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_debug\u001B[0m:\u001B[36m88\u001B[0m - \u001B[34m\u001B[1mUsing prompt for Feedback: Write a draft for a blog post on AI ethics.\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:05.182\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_info\u001B[0m:\u001B[36m83\u001B[0m - \u001B[1mGenerated Feedback: suggestions='Consider discussing the potential biases in AI decision-making, the importance of transparency in AI development, and the need for accountability in AI applications.'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:05.184\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_error\u001B[0m:\u001B[36m98\u001B[0m - \u001B[31m\u001B[1mFailed to generate Feedback with prompt 'Write a draft for a blog post on AI ethics.': 'Feedback' object has no attribute 'analysis'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:05.185\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_debug\u001B[0m:\u001B[36m88\u001B[0m - \u001B[34m\u001B[1mUsing prompt for RefinedDraft: Write a draft for a blog post on AI ethics.\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:05.898\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_info\u001B[0m:\u001B[36m83\u001B[0m - \u001B[1mGenerated RefinedDraft: improved_draft='The rapid development of artificial intelligence has raised significant concerns about its impact on society. As AI becomes increasingly integrated into our daily lives, it is essential to consider the ethical implications of its use. This blog post will explore the key issues surrounding AI ethics, including bias, transparency, and accountability. We will also examine the current state of AI regulation and the steps that can be taken to ensure that AI is developed and used responsibly.'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:05.900\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_error\u001B[0m:\u001B[36m98\u001B[0m - \u001B[31m\u001B[1mFailed to generate RefinedDraft with prompt 'Write a draft for a blog post on AI ethics.': 'RefinedDraft' object has no attribute 'analysis'\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Cycle: [InitialDraft(draft='The ethics of artificial intelligence is a rapidly evolving field that has garnered significant attention in recent years. As AI systems become increasingly integrated into various aspects of our lives, it is essential to consider the moral implications of their development and deployment. This blog post aims to explore the key issues surrounding AI ethics, including transparency, accountability, and fairness.'), None, Feedback(suggestions='Consider discussing the potential biases in AI decision-making, the importance of transparency in AI development, and the need for accountability in AI applications.'), None, RefinedDraft(improved_draft='The rapid development of artificial intelligence has raised significant concerns about its impact on society. As AI becomes increasingly integrated into our daily lives, it is essential to consider the ethical implications of its use. This blog post will explore the key issues surrounding AI ethics, including bias, transparency, and accountability. We will also examine the current state of AI regulation and the steps that can be taken to ensure that AI is developed and used responsibly.'), None]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:48:43.276234Z",
     "start_time": "2024-10-18T01:48:41.579471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Goal(DSLModel):\n",
    "    title: str = Field(..., description=\"Title of the goal.\")\n",
    "    specific: str = Field(..., description=\"Specifics of the goal.\")\n",
    "\n",
    "class Step(DSLModel):\n",
    "    action: str = Field(..., description=\"Action to achieve the goal.\")\n",
    "\n",
    "class Resource(DSLModel):\n",
    "    name: str = Field(..., description=\"Resource needed for the step.\")\n",
    "\n",
    "class GoalPlanning(DSLModel):\n",
    "    goal: Goal = Field(..., description=\"The overarching goal.\")\n",
    "    steps: list[Step] = Field(..., description=\"Steps to achieve the goal.\")\n",
    "    resources: list[Resource] = Field(..., description=\"Resources required.\")\n",
    "\n",
    "initial_prompt = \"Plan for launching a new product in the market.\"\n",
    "models_chain = [Goal, Step, Resource]\n",
    "\n",
    "# Generate goal, steps, and resources using from_prompt_chain\n",
    "planning_result = from_prompt_chain(initial_prompt, models_chain)\n",
    "print(\"Goal Planning:\", planning_result)\n"
   ],
   "id": "78f34077495e383",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-10-17 18:48:41.583\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_debug\u001B[0m:\u001B[36m88\u001B[0m - \u001B[34m\u001B[1mUsing prompt for Goal: Plan for launching a new product in the market.\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:42.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_info\u001B[0m:\u001B[36m83\u001B[0m - \u001B[1mGenerated Goal: title='New Product Launch' specific='Plan for launching a new product in the market.'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:42.575\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_error\u001B[0m:\u001B[36m98\u001B[0m - \u001B[31m\u001B[1mFailed to generate Goal with prompt 'Plan for launching a new product in the market.': 'Goal' object has no attribute 'analysis'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:42.576\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_debug\u001B[0m:\u001B[36m88\u001B[0m - \u001B[34m\u001B[1mUsing prompt for Step: Plan for launching a new product in the market.\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:42.909\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_info\u001B[0m:\u001B[36m83\u001B[0m - \u001B[1mGenerated Step: action='Plan for launching a new product in the market.'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:42.910\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_error\u001B[0m:\u001B[36m98\u001B[0m - \u001B[31m\u001B[1mFailed to generate Step with prompt 'Plan for launching a new product in the market.': 'Step' object has no attribute 'analysis'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:42.911\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_debug\u001B[0m:\u001B[36m88\u001B[0m - \u001B[34m\u001B[1mUsing prompt for Resource: Plan for launching a new product in the market.\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:43.273\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_info\u001B[0m:\u001B[36m83\u001B[0m - \u001B[1mGenerated Resource: name='Plan for launching a new product in the market'\u001B[0m\n",
      "\u001B[32m2024-10-17 18:48:43.274\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mdslmodel.utils.log_tools\u001B[0m:\u001B[36mlog_error\u001B[0m:\u001B[36m98\u001B[0m - \u001B[31m\u001B[1mFailed to generate Resource with prompt 'Plan for launching a new product in the market.': 'Resource' object has no attribute 'analysis'\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Planning: [Goal(title='New Product Launch', specific='Plan for launching a new product in the market.'), None, Step(action='Plan for launching a new product in the market.'), None, Resource(name='Plan for launching a new product in the market'), None]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6bf5cb45dddba5b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
