{
 "cells": [
  {
   "cell_type": "code",
   "id": "d1805e0ee9fbe219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T01:43:20.255465Z",
     "start_time": "2024-10-05T01:43:18.842835Z"
    }
   },
   "source": [
    "import dspy\n",
    "from dslmodel import DSLModel, init_instant\n",
    "from pydantic import Field"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:16:06.932931Z",
     "start_time": "2024-10-08T03:16:05.762267Z"
    }
   },
   "source": [
    "paper_abstract = \"\"\"DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines\n",
    "Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T. Joshi, Hanna Moazam, Heather Miller, Matei Zaharia, Christopher Potts\n",
    "The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded \"prompt templates\", i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, i.e. imperative computational graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn (by creating and collecting demonstrations) how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric. We conduct two case studies, showing that succinct DSPy programs can express and optimize sophisticated LM pipelines that reason about math word problems, tackle multi-hop retrieval, answer complex questions, and control agent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and llama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot prompting (generally by over 25% and 65%, respectively) and pipelines with expert-created demonstrations (by up to 5-46% and 16-40%, respectively). On top of that, DSPy programs compiled to open and relatively small LMs like 770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely on expert-written prompt chains for proprietary GPT-3.5. DSPy is available at this https URL\n",
    "\"\"\"\n",
    "\n",
    "class ArxivPaper(DSLModel):\n",
    "  lead_author: str = Field(description=\"The lead author of the paper\")\n",
    "  co_authors: list[str] = Field(description=\"The co-authors of the paper\")\n",
    "  abstract_summary: str = Field(description=\"The summary of the paper abstract\")\n",
    "\n",
    "init_instant()\n",
    "response = ArxivPaper.from_prompt(paper_abstract)\n",
    "print(response.lead_author)\n",
    "print(response.co_authors)\n",
    "print(response.abstract_summary)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omar Khattab\n",
      "['Arnav Singhvi', 'Paridhi Maheshwari', 'Zhiyuan Zhang', 'Keshav Santhanam', 'Sri Vardhamanan', 'Saiful Haq', 'Ashutosh Sharma', 'Thomas T. Joshi', 'Hanna Moazam', 'Heather Miller', 'Matei Zaharia', 'Christopher Potts']\n",
      "The paper introduces DSPy, a programming model that abstracts language model pipelines as text transformation graphs, and designs a compiler to optimize these pipelines.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "388361dcccc18471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:17:45.912139Z",
     "start_time": "2024-10-08T03:17:44.878214Z"
    }
   },
   "source": [
    "class SentimentModel(DSLModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the sentence. LOWER CASE.\", max_length=5)\n",
    "    confidence: float\n",
    "\n",
    "# Example sentence for sentiment classification\n",
    "sentence = \"This is a bad experience!\"\n",
    "\n",
    "# Define the DSPy signature as a string\n",
    "signature = \"sentence -> sentiment\"\n",
    "\n",
    "init_instant()\n",
    "\n",
    "# Since no predictor_class is provided, dspy.Predict will be used by default\n",
    "response = SentimentModel.from_signature(signature=signature, sentence=sentence)\n",
    "\n",
    "# Access the sentiment from the model instance\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m2024-10-08T03:17:45.398276Z\u001B[0m [\u001B[31m\u001B[1merror    \u001B[0m] \u001B[1mAssertionError: You need to create a kwargs dict for SentimentModel\n",
      "Validation error:\n",
      "1 validation error for SentimentModel\n",
      "sentiment\n",
      "  String should have at most 5 characters [type=string_too_long, input_value='Negative', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_too_long\u001B[0m [\u001B[0m\u001B[1m\u001B[34mdspy.primitives.assertions\u001B[0m]\u001B[0m \u001B[36mfilename\u001B[0m=\u001B[35massertions.py\u001B[0m \u001B[36mlineno\u001B[0m=\u001B[35m88\u001B[0m\n",
      "Error during validation: You need to create a kwargs dict for SentimentModel\n",
      "Validation error:\n",
      "1 validation error for SentimentModel\n",
      "sentiment\n",
      "  String should have at most 5 characters [type=string_too_long, input_value='Negative', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_too_long\n",
      "Output:\n",
      "{'sentiment': 'Negative', 'confidence': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='neg' confidence=0.5\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a04485780ae204b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:18:20.185919Z",
     "start_time": "2024-10-08T03:18:19.747696Z"
    }
   },
   "source": [
    "# Define a DSPy signature class for summarization\n",
    "class SummarizationSignature(dspy.Signature):\n",
    "    \"\"\"Summarize the document.\"\"\"\n",
    "    document = dspy.InputField()\n",
    "    summary = dspy.OutputField(desc=\"10 words or less\")\n",
    "\n",
    "class SummarizationModel(DSLModel):\n",
    "    summary: str = Field(description=\"The summary of the document.\")\n",
    "\n",
    "# Example document for summarization\n",
    "document = \"\"\"The first of the month is coming, we have to get money, we have no choice. It cost money to eat and they don’t want you to eat. Life is what you make it, so let’s make it. They don’t want us to win. Look at the sunset, life is amazing, life is beautiful, life is what you make it. Don’t ever play yourself. Hammock talk come soon. Special cloth alert. Learning is cool, but knowing is better, and I know the key to success. Eliptical talk. Let’s see what Chef Dee got that they don’t want us to eat. Give thanks to the most high. Give thanks to the most high.\n",
    "\n",
    "The key is to drink coconut, fresh coconut, trust me. Congratulations, you played yourself. The weather is amazing, walk with me through the pathway of more success. Take this journey with me, Lion! Egg whites, turkey sausage, wheat toast, water. Of course they don’t want us to eat our breakfast, so we are going to enjoy our breakfast. The key to success is to keep your head above the water, never give up. The key is to enjoy life, because they don’t want you to enjoy life. I promise you, they don’t want you to jetski, they don’t want you to smile.\n",
    "\n",
    "Look at the sunset, life is amazing, life is beautiful, life is what you make it. They don’t want us to win. They key is to have every key, the key to open every door. Another one. Always remember in the jungle there’s a lot of they in there, after you overcome they, you will make it to paradise. Don’t ever play yourself. They never said winning was easy. Some people can’t handle success, I can. To be successful you’ve got to work hard, to make history, simple, you’ve got to make it. They key is to have every key, the key to open every door.\"\"\"\n",
    "\n",
    "# Using a signature class and providing a custom predictor class (e.g., dspy.ChainOfThought)\n",
    "response = SummarizationModel.from_signature(signature=SummarizationSignature, \n",
    "                                             predictor_class=dspy.ChainOfThought, \n",
    "                                             document=document,\n",
    "                                             verbose=True)\n",
    "\n",
    "# Access the summary from the model instance\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Prediction(\n",
      "    reasoning=\"The document appears to be a motivational speech or poem, encouraging the reader to take control of their life, be successful, and not let others bring them down. It emphasizes the importance of perseverance, hard work, and being mindful of one's surroundings.\",\n",
      "    summary='Motivational speech on success and perseverance.'\n",
      ")\n",
      "Prompt: Prediction(\n",
      "    reasoning=\"The document appears to be a motivational speech or poem, encouraging the reader to take control of their life, be successful, and not let others bring them down. It emphasizes the importance of perseverance, hard work, and being mindful of one's surroundings.\",\n",
      "    summary='Motivational speech on success and perseverance.'\n",
      ")\n",
      "summary='Motivational speech on success and perseverance.'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "fe01937e63a8bf26",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
