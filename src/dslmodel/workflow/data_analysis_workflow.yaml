name: DataAnalysisWorkflow
triggers:
  - cron: "0 0 * * *"  # Run daily at midnight
  - cron: "0 */4 * * *"  # Run every 4 hours
imports:
  - /Users/sac/dev/dspygen/src/dspygen/workflow/data_preparation_workflow.yaml
jobs:
  - name: AnalyzeData
    runner: python
    depends_on:
      - PrepareData
    steps:
      - name: LoadFilteredData
        code: |
          import json
          global filtered_data
          with open(filtered_data_path, 'r') as f:
              filtered_data = json.load(f)
        env: {}

      - name: CalculateAverage
        code: |
          average_value = sum(item['value'] for item in filtered_data) / len(filtered_data)
          print(f'Average value: {average_value}')

          from dspygen.dsl.dsl_pipeline_executor import execute_pipeline
          context = execute_pipeline('/Users/sac/dev/dspygen/tests/pipeline/data_hello_world_pipeline.yaml', init_ctx={"csv_file": "/Users/sac/dev/dspygen/tests/data/greek.csv"})
          print(context)
        env: {}
